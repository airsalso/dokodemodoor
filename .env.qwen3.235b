# ═══════════════════════════════════════════════════════════════════
# DokodemoDoor — PRODUCTION Environment
# Model: Qwen/Qwen3-235B-A22B (MoE 235B total / 22B active)
#   - 94 layers, 64 Q-heads / 4 KV-heads (GQA), 128 experts / 8 active
#   - Context: 32,768 tokens native | 131,072 tokens with YaRN
# ═══════════════════════════════════════════════════════════════════

# ── LLM Provider ──────────────────────────────────────────────────
DOKODEMODOOR_LLM_PROVIDER=vllm
VLLM_BASE_URL=http://localhost:8000/v1
VLLM_MODEL=Qwen/Qwen3-235B-A22B
VLLM_API_KEY=EMPTY

# ── LLM Parameters ───────────────────────────────────────────────
# Temperature: 0.1 — precise, deterministic output for production assessments.
# 235B model follows instructions well at low temperature.
VLLM_TEMPERATURE=0.1

# ── Turn Budgets ──────────────────────────────────────────────────
# 235B model: highly capable per turn. More turns = deeper, more thorough analysis.
# Production assessments should be exhaustive.
#
#   Model capacity factor: ~1.0x baseline (flagship model)
#   Strategy: generous turns for complete coverage
VLLM_MAX_TURNS=300

# Agent-specific overrides
#   pre-recon: full codebase scan, needs many turns for large repos
#   recon: thorough runtime discovery + verification
#   osv: iterate over all dependencies + AI analysis
#   fuzzer: API fuzzing needs many request cycles
#   report: consolidation should converge quickly with strong model
# 실행 시간 단축 권장: PRERECON 200~300, RECON 200~250
DOKODEMODOOR_PRERECON_MAX_TURNS=250
DOKODEMODOOR_RECON_MAX_TURNS=250
DOKODEMODOOR_OSV_MAX_TURNS=500
DOKODEMODOOR_API_FUZZER_MAX_TURNS=300
DOKODEMODOOR_REPORT_MAX_TURNS=200

# ── Prompt Size Limits ────────────────────────────────────────────
# ┌───────────────────────────────────────────────────────────────┐
# │ Native context (32,768 tokens) — DEFAULT                     │
# │   reserve       = ~30% for completion = ~9,830 tokens         │
# │   prompt budget = ~22,938 tokens                              │
# │   chars/token   ≈ 3.5 (Korean + English + code mix)           │
# │   safe limit    = 22,938 × 3.5 ≈ 80,283 → round to 85,000   │
# │                                                               │
# │ NOTE: Observed 400 error at ~121K chars (~34.5K tokens)       │
# │   which confirms the 32K native ceiling.                      │
# ├───────────────────────────────────────────────────────────────┤
# │ YaRN extended context (131,072 tokens) — OPTIONAL             │
# │   If vLLM is launched with --max-model-len 131072             │
# │   and rope_scaling configured for YaRN:                       │
# │   reserve       = ~12% = ~15,728 tokens                      │
# │   prompt budget = ~115,344 tokens                             │
# │   safe limit    = 115,344 × 3.5 ≈ 403K → use 350,000        │
# │                                                               │
# │   To enable, uncomment and replace:                           │
# │   VLLM_MAX_PROMPT_CHARS=350000                                │
# │   DOKODEMODOOR_CONTEXT_COMPRESSION_THRESHOLD=280000           │
# │   DOKODEMODOOR_CONTEXT_COMPRESSION_WINDOW=30                  │
# │   DOKODEMODOOR_SUB_AGENT_TRUNCATE_LIMIT=50000                 │
# └───────────────────────────────────────────────────────────────┘
VLLM_MAX_PROMPT_CHARS=85000

# Model context size in tokens. Must match vLLM model's max_model_len (curl http://localhost:8000/v1/models → "max_model_len"). Default 32768; use 65536 for 65k models.
# VLLM_MAX_CONTEXT_TOKENS=65536

# ── Token Pricing ─────────────────────────────────────────────────
# Self-hosted production. Adjust if using external API endpoint.
VLLM_PROMPT_TOKEN_PRICE=0.0
VLLM_COMPLETION_TOKEN_PRICE=0.0

# ── Sub-Agent Configuration ───────────────────────────────────────
# Strong model produces focused output. More turns + longer context allowed.
DOKODEMODOOR_SUB_AGENT_MAX_TURNS=30
DOKODEMODOOR_SUB_AGENT_TRUNCATE_LIMIT=30000

# ── Context Compression ──────────────────────────────────────────
# Triggers at ~76% of VLLM_MAX_PROMPT_CHARS (65K / 85K).
# Keeps 20 recent messages — larger window for deeper conversation history.
DOKODEMODOOR_CONTEXT_COMPRESSION_THRESHOLD=65000
DOKODEMODOOR_CONTEXT_COMPRESSION_WINDOW=20

# ── Debug & Logging ───────────────────────────────────────────────
# Production: minimal debug noise, keep audit logs
DOKODEMODOOR_DEBUG=false
DOKODEMODOOR_PRINT_LOG_PROMPT_SIZES=false
DOKODEMODOOR_DISABLE_LOADER=false
DOKODEMODOOR_AGENT_DEBUG_LOG=true

# ── Tool Availability ────────────────────────────────────────────
# Production: run ALL tools for comprehensive assessment
DOKODEMODOOR_SKIP_TOOL_CHECK=false
DOKODEMODOOR_SKIP_NMAP=false
DOKODEMODOOR_SKIP_SUBFINDER=false
DOKODEMODOOR_SKIP_WHATWEB=false
DOKODEMODOOR_SKIP_SCHEMATHESIS=false
DOKODEMODOOR_SKIP_SEMGREP=false
DOKODEMODOOR_SKIP_OSV=false

# ── Pipeline Control ─────────────────────────────────────────────
# Production: full pipeline including exploitation
DOKODEMODOOR_SKIP_EXPLOITATION=false

# ── Playwright ────────────────────────────────────────────────────
# Headless for production (no display needed)
DOKODEMODOOR_PLAYWRIGHT_HEADLESS=true

# ── Concurrency ───────────────────────────────────────────────────
# Multi-GPU production server.
# 4 parallel agents: balances throughput vs. vLLM queue depth.
# Adjust based on GPU count (rule of thumb: parallel_limit ≤ GPU count).
DOKODEMODOOR_PARALLEL_LIMIT=4

# ── External Testing ─────────────────────────────────────────────
# MUST point to an attacker-controlled callback server for SSRF/OOB tests.
EXTERNAL_TEST_DOMAIN=http://attacker-controlled.com
